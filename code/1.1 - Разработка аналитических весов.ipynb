{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 - Рассчет аналитических весов\n",
    "\n",
    "**Цель:** Разработать аналитические веса для рейтингов\n",
    "\n",
    "При расчете весов рейтингов используется трехкомпонентный расчет, где каждый компонент отвечает за определенный аспект корректировки влияния рейтинга на модель. Такая структура позволяет независимо контролировать временные эффекты, продолжительность действия и балансировку классов.\n",
    "- Учет к-во расчетов в день рейтинга\n",
    "- Учет длины валидного периода\n",
    "- Учет дисбаланса классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 - Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import yaml\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import yaml\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.subplots as sp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 - Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../CONFIGS.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHS = config['data_paths']\n",
    "PARAMS = config['calibration_params']\n",
    "\n",
    "filepath = {\n",
    "      'clean_data' : PATHS['other']['clean_data']\n",
    "    , 'valid_dates' : PATHS['ratings']['valid_dates']\n",
    "    , 'rating_weights': PATHS['ratings']['weights']\n",
    "}\n",
    "\n",
    "annual_drs = config['calibration_params']['annual_drs']\n",
    "ttc_ratio = config['calibration_params']['central_tendency']['TTC']\n",
    "pit_ratio = config['calibration_params']['central_tendency']['PIT']\n",
    "\n",
    "pit_quarters = [str(y)+'Q'+str(q) for y, q in PARAMS['pit_quarters']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annual_default_pcts = config['calibration_params']['annual_drs']\n",
    "# ttc_pct = config['calibration_params']['central_tendency']['TTC']\n",
    "# pit_pct = config['calibration_params']['central_tendency']['PIT']\n",
    "# annual_drs = {y: p / 100 for y, p in list(annual_default_pcts.items()) if p >= 0 and p<=100}\n",
    "# ttc_ratio = ttc_pct / 100\n",
    "# pit_ratio = pit_pct / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(filepath['clean_data'])\n",
    "data['rating_assignment_date'] = pd.to_datetime(data['rating_assignment_date'].dt.date)\n",
    "\n",
    "valid_dates = pd.read_parquet(filepath['valid_dates'])\n",
    "valid_dates = valid_dates.drop('rating_assignment_date', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define colors for each weight type\n",
    "colors = {\n",
    "    'weight_day': '#FF6B6B',\n",
    "    'weight_1': '#4ECDC4', \n",
    "    'weight_2': '#45B7D1',\n",
    "    'W': '#96CEB4'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.3 - Функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing_pct(df):\n",
    "    stats = round(df.isna().sum()/ df.shape[0] * 100, 2).sort_values(ascending=False)\n",
    "    stats_only_missing = stats.loc[stats.index[stats>0]].to_frame().rename(columns={0:'missing_pct'})\n",
    "    return stats_only_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_example(data, example_client=706021):\n",
    "    return data.query('client_id == @example_client')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_daily_weights(df):\n",
    "    \"\"\"\n",
    "    Расчет веса каждого дня - обратно пропорционально количеству активных рейтингов.\n",
    "    \"\"\"\n",
    "    daily_weights = []\n",
    "    \n",
    "    for date in df.rating_assignment_date.sort_values().unique():\n",
    "        active_ratings_count = df[\n",
    "            (df['rating_assignment_date'] <= date) & \n",
    "            (df['valid_date'] > date)\n",
    "        ].shape[0]\n",
    "        \n",
    "        daily_weights.append({\n",
    "            'rating_assignment_date': date,\n",
    "            'weight_day': 1 / active_ratings_count if active_ratings_count > 0 else 0\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(daily_weights)\n",
    "\n",
    "\n",
    "def normalize_weights_by_year(weights_df, target_distribution=None):\n",
    "    \"\"\"\n",
    "    Нормализация весов так, чтобы каждый год имел заданную долю.\n",
    "    \"\"\"\n",
    "    weights_df = weights_df.copy()\n",
    "    weights_df['year'] = weights_df['rating_assignment_date'].dt.year\n",
    "    unique_years = weights_df['year'].unique()\n",
    "    \n",
    "    if target_distribution is None:\n",
    "        target_distribution = {year: 1.0 / len(unique_years) for year in unique_years}\n",
    "    \n",
    "    weights_df['weight_day_normalized'] = weights_df['weight_day'].copy()\n",
    "    \n",
    "    for year in unique_years:\n",
    "        year_mask = weights_df['year'] == year\n",
    "        year_sum = weights_df.loc[year_mask, 'weight_day'].sum()\n",
    "        \n",
    "        if year_sum > 0 and year in target_distribution:\n",
    "            scaling_factor = target_distribution[year] / year_sum\n",
    "            weights_df.loc[year_mask, 'weight_day_normalized'] *= scaling_factor\n",
    "    \n",
    "    weights_df['weight_day'] = weights_df['weight_day_normalized']\n",
    "    weights_df = weights_df.drop(['weight_day_normalized', 'year'], axis=1)\n",
    "    \n",
    "    return weights_df\n",
    "\n",
    "\n",
    "def calculate_validity_period_weight(df):\n",
    "    \"\"\"Расчет weight_1: сумма весов дней на валидном периоде каждого рейтинга\"\"\"\n",
    "    df['weight_1'] = 0\n",
    "    for i in range(len(df)):\n",
    "        client     = df.client_id.iloc[i]\n",
    "        date_start = df.rating_assignment_date.iloc[i]\n",
    "        date_end   = df.valid_date.iloc[i]\n",
    "        df.weight_1.iloc[i] = df[(df['rating_assignment_date'] >= date_start) & (df['rating_assignment_date'] <= date_end)]['weight_day'].sum()\n",
    "    return df['weight_1']\n",
    "\n",
    "\n",
    "def apply_outlier_filter(df: pd.DataFrame, col: str, quantile_range=(0.005, 0.995)) -> pd.DataFrame:\n",
    "    lower_bound = df[col].quantile(quantile_range[0])\n",
    "    upper_bound = df[col].quantile(quantile_range[1])\n",
    "    return df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "\n",
    "\n",
    "def get_yearly_stats(df, target_default_rates):\n",
    "    df['year']      = df['rating_assignment_date'].dt.year\n",
    "    df['target_dr'] = df['year'].map(lambda y: target_default_rates.get(y))\n",
    "\n",
    "    # Подсчет статистики по годам\n",
    "    yearly_stats = df.groupby('year').agg({\n",
    "        'target': ['sum', 'count', 'mean']\n",
    "    }).reset_index()\n",
    "    yearly_stats.columns = ['year', 'defaults_count', 'total_count', 'default_rate']\n",
    "    \n",
    "    # df = df.merge(yearly_stats, on='year', how='left')\n",
    "\n",
    "    return yearly_stats\n",
    "\n",
    "\n",
    "def assign_annual_drs(df, annual_drs):\n",
    "    from dateutil.relativedelta import relativedelta\n",
    "\n",
    "    min_year = df['rating_assignment_date'].min().year\n",
    "    max_year = df['rating_assignment_date'].max().year\n",
    "    start_date = pd.to_datetime(str(min_year) + '-01-01', format='%Y-%m-%d')\n",
    "\n",
    "    # print(f\"Years range: {min_year} to {max_year}\")\n",
    "    # print(f\"Number of years: {max_year - min_year + 1}\")\n",
    "    # print(f\"Length of ct: {len(annual_drs.values())}\")\n",
    "\n",
    "    df['drp'] = 0\n",
    "\n",
    "    while start_date.year <= max_year:\n",
    "        end_date = start_date + relativedelta(years=1)\n",
    "        \n",
    "        ratings_within_year = df.query('@start_date <= rating_assignment_date < @end_date').copy()\n",
    "        shape    = ratings_within_year.shape[0]\n",
    "        defaults = ratings_within_year.target.sum()\n",
    "        \n",
    "        # Check if index is valid before using it\n",
    "        if start_date.year in annual_drs.keys():\n",
    "            drp_value = annual_drs[start_date.year]\n",
    "        else:\n",
    "            print(f\"Warning: No ct value for the year {start_date.year}\")\n",
    "            break\n",
    "        \n",
    "        \n",
    "        df.loc[(start_date <= df.rating_assignment_date) & (df.rating_assignment_date < end_date), 'drp'] = drp_value\n",
    "        df.loc[(start_date <= df.rating_assignment_date) & (df.rating_assignment_date < end_date), 'total'] = shape\n",
    "        df.loc[(start_date <= df.rating_assignment_date) & (df.rating_assignment_date < end_date), 'defaults'] = defaults\n",
    "        \n",
    "        start_date = end_date\n",
    "\n",
    "    return df \n",
    "\n",
    "\n",
    "def calculate_weight_2(df):\n",
    "    \"\"\"\n",
    "    Расчет weight_2 для ребалансировки классов\n",
    "    \"\"\"\n",
    "    non_defaults_count = df['total'] - df['defaults']\n",
    "    \n",
    "    # Определяем, в каком формате drp и приводим к долям\n",
    "    if ((df['drp'] >= 0 )& (df['drp'] <= 1)).all():\n",
    "        drp_ratio = df['drp']\n",
    "    elif ((df['drp'] >= 0) & (df['drp'] <= 100)).all():\n",
    "        drp_ratio = df['drp'] / 100 \n",
    "    else:\n",
    "        print('Error')\n",
    "        return None\n",
    "    \n",
    "    non_defaults_ratio = 1 - drp_ratio\n",
    "    \n",
    "    # Расчет веса для не-дефолтов\n",
    "    # Используем drp (ratio) везде для консистентности\n",
    "    df['weight_2'] = (drp_ratio * non_defaults_count) / (df['defaults'] * non_defaults_ratio)\n",
    "    \n",
    "    # Вес для дефолтов\n",
    "    df.loc[df['target'] == 1, 'weight_2'] = 1\n",
    "    \n",
    "    return df['weight_2']\n",
    "\n",
    "\n",
    "def calculate_final_weight(weight_1:pd.Series, weight_2: pd.Series):\n",
    "    return weight_1 * weight_2\n",
    "\n",
    "\n",
    "def calculate_weights(data, valid_dates, target_default_rates, target_ttc, target_pit, normalise=False):\n",
    "    \"\"\"\n",
    "    Базовый расчет весов с учетом временной валидности и целевых DR\n",
    "    \"\"\"\n",
    "\n",
    "    df = data.merge(valid_dates, on=['client_id', 'rating_id'])\n",
    "    \n",
    "    df['year_quarter'] = df['rating_assignment_date'].dt.to_period('Q')\n",
    "    \n",
    "    # Рассчитываем веса для уникальных дат\n",
    "    daily_weights = calculate_daily_weights(df)\n",
    "    \n",
    "    # Нормализуем если нужно\n",
    "    if normalise:\n",
    "        daily_weights = normalize_weights_by_year(daily_weights)\n",
    "    \n",
    "    # Merge весов обратно в основной DataFrame\n",
    "    df = df.merge(daily_weights, on='rating_assignment_date', how='left')\n",
    "    \n",
    "    # Остальная логика остается без изменений\n",
    "    df['weight_1'] = calculate_validity_period_weight(df)\n",
    "    # df = apply_outlier_filter(df=df, col='weight_1')\n",
    "    df = assign_annual_drs(df, target_default_rates)\n",
    "    df['weight_2'] = calculate_weight_2(df)\n",
    "    df['W'] = calculate_final_weight(weight_1=df['weight_1'], weight_2=df['weight_2'])\n",
    "    df['W'] = calibrate_weights_to_target_dr(df, target_ttc=target_ttc)\n",
    "    \n",
    "    return df[['client_id', 'rating_id', 'weight_day', 'weight_1', 'weight_2', 'W']]\n",
    "\n",
    "def calibrate_weights_to_target_dr(df, target_ttc, weight_col='W'):\n",
    "    \"\"\"\n",
    "    Калибрует веса так, чтобы:\n",
    "    1. Взвешенный default rate = target_ttc\n",
    "    2. Сумма всех весов = количеству наблюдений\n",
    "    \"\"\"\n",
    "    total_observations_N = df.shape[0]\n",
    "    target_defaults_N = total_observations_N * target_ttc \n",
    "    \n",
    "    # Шаг 1: Масштабируем веса дефолтов\n",
    "    defaults_weight_sum    = df[df['target'] == 1][weight_col].sum()\n",
    "    default_scaling_factor = target_defaults_N / defaults_weight_sum\n",
    "    df.loc[df.target == 1, weight_col] = df[weight_col] * default_scaling_factor\n",
    "    \n",
    "    # Шаг 2: Масштабируем веса не-дефолтов\n",
    "    new_defaults_weight_sum    = df[df['target'] == 1][weight_col].sum()\n",
    "    non_defaults_weight_sum    = df[df['target'] == 0][weight_col].sum()\n",
    "    target_non_defaults_count  = total_observations_N - new_defaults_weight_sum\n",
    "    non_default_scaling_factor = target_non_defaults_count / non_defaults_weight_sum\n",
    "    df.loc[df.target == 0, weight_col] = df[weight_col] * non_default_scaling_factor\n",
    "    \n",
    "    return df[weight_col]\n",
    "\n",
    "\n",
    "def validate_weights(df, weight_col, target_ttc, target_pit, pit_quarters, rounding_to=5):\n",
    "    W_target   = df[df.target == 1][weight_col].sum()\n",
    "    W_notarget = df[df.target == 0][weight_col].sum()\n",
    "    current_ttc = W_target / (W_target + W_notarget) \n",
    "    if round(current_ttc, rounding_to) == round(target_ttc, rounding_to):\n",
    "        print('✅ Получившийся TTC равен целевому (c округлением)')\n",
    "    else:\n",
    "        print('❌ Получившийся TTC НЕ равен целевому.')\n",
    "    print(current_ttc, target_ttc)\n",
    "\n",
    "    pit_check_df    = df.copy()\n",
    "    pit_check_df['year_quarter'] = pit_check_df['rating_assignment_date'].dt.to_period('Q')\n",
    "    pit_quarters    = pd.PeriodIndex(pit_quarters, freq='Q')\n",
    "    W_pit           = pit_check_df.query('year_quarter.isin(@pit_quarters)', engine = 'python')\n",
    "    W_pit_target    = W_pit[W_pit.target == 1][weight_col].sum()\n",
    "    W_pit_nontarget = W_pit[W_pit.target == 0][weight_col].sum()\n",
    "    current_pit = W_pit_target / (W_pit_target + W_pit_nontarget)\n",
    "    \n",
    "    if round(current_pit, rounding_to) == round(target_pit, rounding_to):\n",
    "        print('✅ Получившийся PIT равен целевому (c округлением).')\n",
    "    else:\n",
    "        print('❌ Получившийся PIT НЕ равен целевому.')\n",
    "    print(current_pit, target_pit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 - Расчет весов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_df = calculate_weights( data=data\n",
    "                              , valid_dates=valid_dates\n",
    "                              , target_default_rates=annual_drs\n",
    "                              , target_ttc=ttc_ratio\n",
    "                              , target_pit=pit_ratio\n",
    "                              , normalise=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_weights_df = calculate_weights( data=data\n",
    "                                         , valid_dates=valid_dates\n",
    "                                         , target_default_rates=annual_drs\n",
    "                                         , target_ttc=ttc_ratio\n",
    "                                         , target_pit=pit_ratio\n",
    "                                         , normalise=True)\n",
    "normalised_weights_df.rename(columns={  'weight_day': 'weight_day_norm'\n",
    "                                      , 'weight_1'  : 'weight_1_norm'\n",
    "                                      , 'weight_2'  : 'weight_2_norm'\n",
    "                                      , 'W'         : 'W_norm'\n",
    "                                      }\n",
    "                            , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_weights_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (data[['client_id', 'rating_id', 'rating_assignment_date', 'target']]\n",
    "        .merge(valid_dates, on=['client_id', 'rating_id'], how='inner')\n",
    "        .merge(weights_df, on=['client_id', 'rating_id'], how='inner')\n",
    "        .merge(normalised_weights_df, on=['client_id', 'rating_id'], how='inner'))\n",
    "\n",
    "df['year'] = df['rating_assignment_date'].dt.year\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_save = [\n",
    "#       'client_id', 'rating_id', 'rating_assignment_date', 'valid_date'\n",
    "#     , 'total', 'defaults', 'drp', 'target'\n",
    "#     , 'weight_day', 'weight_1', 'weight_2', 'W'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_cols =  ['weight_day', 'weight_1', 'weight_2', 'W', 'weight_day_norm', 'weight_1_norm', 'weight_2_norm', 'W_norm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.5 - Визуализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== COMBINED VIOLIN PLOT WITH DUAL Y-AXIS =====\n",
    "fig_violin = sp.make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "\n",
    "# ===== HISTOGRAM =====\n",
    "fig_hist = sp.make_subplots(\n",
    "    rows=2, cols=4,\n",
    "    subplot_titles=('weight_day', 'weight_1', 'weight_2', 'W',\n",
    "                   'weight_day_norm', 'weight_1_norm', 'weight_2_norm', 'W_norm'),\n",
    "    vertical_spacing=0.15,\n",
    "    horizontal_spacing=0.05\n",
    ")\n",
    "\n",
    "# Original weights histograms (top row)\n",
    "weight_names = ['weight_day', 'weight_1', 'weight_2', 'W']\n",
    "for i, col in enumerate(weight_names):\n",
    "    fig_hist.add_trace(\n",
    "        go.Histogram(\n",
    "            x=df[col],\n",
    "            name=col,\n",
    "            marker_color=colors[col],\n",
    "            opacity=0.7,\n",
    "            nbinsx=20\n",
    "        ),\n",
    "        row=1, col=i+1\n",
    "    )\n",
    "\n",
    "# Normalized weights histograms (bottom row)\n",
    "norm_names = ['weight_day_norm', 'weight_1_norm', 'weight_2_norm', 'W_norm']\n",
    "for i, col in enumerate(norm_names):\n",
    "    base_name = col.replace('_norm', '')\n",
    "    fig_hist.add_trace(\n",
    "        go.Histogram(\n",
    "            x=df[col],\n",
    "            name=col,\n",
    "            marker_color=colors[base_name],\n",
    "            opacity=0.7,\n",
    "            nbinsx=20\n",
    "        ),\n",
    "        row=2, col=i+1\n",
    "    )\n",
    "\n",
    "fig_hist.update_layout(\n",
    "    title_text=\"Histogram: Weight Distribution Comparison\",\n",
    "    title_font_size=16,\n",
    "    height=600,\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "print(\"\\nDisplaying Histogram...\")\n",
    "fig_hist.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Агрегация данных\n",
    "stats_df = df.groupby('year').agg({\n",
    "    'rating_assignment_date': 'count',\n",
    "    'client_id': 'nunique'\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns\n",
    "stats_df.columns = ['year', 'total', 'clients']\n",
    "\n",
    "# ===== ГРАФИК С ДВУМЯ СТОЛБЦАМИ РЯДОМ =====\n",
    "fig = go.Figure()\n",
    "\n",
    "# Общее количество записей\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=stats_df['year'],\n",
    "        y=stats_df['total'],\n",
    "        name='Общее количество рейтингов',\n",
    "        marker_color='grey',\n",
    "        opacity=0.7,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Количество клиентов\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=stats_df['year'],\n",
    "        y=stats_df['clients'],\n",
    "        name='Количество клиентов',\n",
    "        marker_color='blue'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=dict(\n",
    "        text=\"Статистика портфеля по годам\",\n",
    "        x=0.5,  # Центрируем заголовок\n",
    "        xanchor='center'  # Выравниваем по центру\n",
    "    ),\n",
    "    width=1000,\n",
    "    height=400,\n",
    "    xaxis=dict(\n",
    "        title=dict(\n",
    "            text=\"Год\",\n",
    "        ),\n",
    "        tickmode='linear',\n",
    "        dtick=1,\n",
    "        showgrid=False,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=dict(\n",
    "            text=\"Количество\",\n",
    "        ),\n",
    "        showgrid=True,\n",
    "        gridcolor='lightgray',  # Light gray gridlines\n",
    "        gridwidth=0.5,          # Thin gridlines\n",
    "    ),\n",
    "    barmode='group',\n",
    "    plot_bgcolor='white',\n",
    "    showlegend=True,\n",
    "    legend=dict(\n",
    "        orientation=\"h\",  # Горизонтальная легенда\n",
    "        yanchor=\"top\",    # Привязка к верхней части\n",
    "        y=-0.3,           # Размещение внизу (отрицательное значение)\n",
    "        xanchor=\"center\", # Центрирование по горизонтали\n",
    "        x=0.5,            # Центр по горизонтали\n",
    "        bgcolor='white',\n",
    "        bordercolor='black',\n",
    "        borderwidth=1\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# ===== BOX PLOT BY YEAR FOR W and W_norm =====\n",
    "fig_yearly = go.Figure()\n",
    "\n",
    "df['year'] = df['rating_assignment_date'].dt.year\n",
    "years = sorted(df['year'].unique())\n",
    "\n",
    "# Add W (original) by year - only add legend for first trace\n",
    "for i, year in enumerate(years):\n",
    "    year_data = df[df['year'] == year]\n",
    "    fig_yearly.add_trace(\n",
    "        go.Box(\n",
    "            y=year_data['weight_day'],\n",
    "            name='Ненормализованный вес' if i == 0 else '',  # Only show legend for first trace\n",
    "            fillcolor='blue',\n",
    "            line_color='blue',\n",
    "            offsetgroup=1,\n",
    "            x=[f'{year}'] * len(year_data),\n",
    "            legendgroup='original',  # Group for legend\n",
    "            showlegend=True if i == 0 else False  # Only show legend for first trace\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Add W_norm (normalized) by year - only add legend for first trace\n",
    "for i, year in enumerate(years):\n",
    "    year_data = df[df['year'] == year]\n",
    "    fig_yearly.add_trace(\n",
    "        go.Box(\n",
    "            y=year_data['weight_day_norm'],\n",
    "            name='Нормализованный вес' if i == 0 else '',  # Only show legend for first trace\n",
    "            fillcolor='green',\n",
    "            line_color='green',\n",
    "            offsetgroup=2,\n",
    "            x=[f'{year}'] * len(year_data),\n",
    "            legendgroup='normalized',  # Group for legend\n",
    "            showlegend=True if i == 0 else False  # Only show legend for first trace\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig_yearly.update_layout(\n",
    "    title=dict(\n",
    "        text=\"Ненормализованный и нормализованный итоговый вес\",\n",
    "        x=0.5,\n",
    "        xanchor='center',\n",
    "        font=dict(size=18)\n",
    "    ),\n",
    "    height=600,\n",
    "    width=1200,\n",
    "    xaxis=dict(\n",
    "        title=dict(text=\"Год\", font=dict(size=18)),\n",
    "        tickfont=dict(size=16),\n",
    "        showgrid=False,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title=dict(text=\"Вес\", font=dict(size=16)),\n",
    "        tickfont=dict(size=16),\n",
    "        showgrid=True,\n",
    "        gridcolor='lightgray',\n",
    "        gridwidth=0.5,\n",
    "    ),\n",
    "    boxmode='group',\n",
    "    plot_bgcolor='white',\n",
    "    paper_bgcolor='white',\n",
    "    showlegend=True,\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"top\",\n",
    "        y=-0.3,\n",
    "        xanchor=\"center\",\n",
    "        x=0.5,\n",
    "        bgcolor='white',\n",
    "        bordercolor='black',\n",
    "        borderwidth=1,\n",
    "        font=dict(size=16)\n",
    "    ),\n",
    "    font=dict(size=16)\n",
    ")\n",
    "\n",
    "print(\"Displaying Bar Chart...\")\n",
    "# fig.show()\n",
    "print(\"\\nDisplaying Yearly Box Plot for W and W_norm...\")\n",
    "fig_yearly.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.6 -Валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_weights(df, weight_col='W', target_ttc=ttc_ratio, target_pit=pit_ratio, pit_quarters=pit_quarters)\n",
    "print('----')\n",
    "validate_weights(df, weight_col='W_norm', target_ttc=ttc_ratio, target_pit=pit_ratio, pit_quarters=pit_quarters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.7 - Выгрузка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df.copy().sort_values(['rating_assignment_date', 'rating_id', 'client_id']).drop(['year'], axis=1)\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_parquet(filepath['rating_weights'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
